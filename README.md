# MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark

[**ğŸ“„ MMSU arXiv**](https://arxiv.org/pdf/2506.04779) | [**ğŸ§ Demo Page**](https://ddw.github.io/mmsu_homepage/) | [**ğŸ† Leaderboard**](https://sakshi113.github.io/mmau_homepage/#leaderboard-v15-parsed) | [**ğŸ¤— Dataset Download**](https://huggingface.co/datasets/ddwang2000/MMSU) 

## Overview

MMSU (Massive Multi-task Spoken Language Understanding and Reasoning Benchmark) is a comprehensive benchmark for evaluating fine-grained spoken language understanding and reasoning in multimodal models. It systematically captures the variance of real-world linguistic phenomena in daily speech through 47 sub-tasks, including phonetics, prosody, rhetoric, syntactics, semantics, and paralinguistics, spanning both perceptual and higher-level reasoning capabilities. The benchmark comprises 5,000 carefully curated audioâ€“questionâ€“answer pairs derived from diverse authentic recordings.

![Alt text](images/example.png)

MMSU adopts a three-level taxonomy to organize tasks and assessment dimensions. **At the first level**, it distinguishes between perception and reasoning abilities. **At the second level**, both are divided into linguistics and paralinguistics.  Linguistics concerns language structure, meaning, and usage, whereas paralinguistics captures vocal characteristics that influence interpretation, such as emotion, pitch, and volume. **At the third level**, linguistics further branches into semantics and phonology, covering meaning and contextual understanding versus sound patterns such as tone and prosody.  Paralinguistics is divided into speaker traits, reflecting inherent vocal characteristics, and speaking style, capturing variable expressive elements.

![Alt text](images/mmsu_benchmark.png)

## 
